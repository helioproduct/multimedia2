# multimedia2

# lab07


## Сводная таблица результатов лабораторной работы №7

| Модель                          | Pixel Acc | IoU    |
|---------------------------------|-----------|--------|
| SMP-Unet + ResNet34  | 0.9817    | 0.7239 |
| SMP-Unet + ResNet34    | 0.9878    | 0.7961 |
| Собственная U-Net    | 0.9877    | 0.8014 |
| Собственная U-Net      | 0.9854    | 0.7680 |


# lab08

## Сводная таблица результатов эксперимента по обнаружению объектов

| Модель                | Precision | Recall  | mAP50  | mAP50-95 | Fitness |
|-----------------------|-----------|---------|--------|----------|---------|
| YOLO baseline         | 0.8714    | 0.8746  | 0.9124 | 0.6671   | 0.6916  |
| YOLO improved         | 0.8393    | 0.8731  | 0.9091 | 0.6762   | 0.6995  |
| Yolo (собственная имплементация)   | 0.000     | 0.000   | –      | –        | –       |
| Yolo (собственная имплементация improved)   | 0.000     | 0.000   | –      | –        | –       |


В результате экспериментов:

    Сегментация: предобученный SMP-U-Net + ResNet34 без аугментаций дал IoU≈0.72, с аугментациями — IoU≈0.80; собственная U-Net показывала сравнимые результаты без аугментаций, но при добавлении аугментаций стала менее устойчива.

    Детекция (YOLOv8n): базовый mAP50≈0.91 и mAP50-95≈0.67, после донастройки и аугментаций mAP50-95 вырос до ≈0.68, вырос и общий “fitness”.

Вывод: мощные предобученные модели с готовыми архитектурами оказываются более стабильными и точными «из коробки», тогда как собственные реализации требуют огромных усилий при работе с полными датасетами, чтобы не сталкиваться с проблемами сложности архитектуры, долгого обучения и нестабильности сходимости.
